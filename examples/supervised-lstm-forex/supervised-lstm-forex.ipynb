{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import pyfinancialdata\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "units = 25\n",
    "epoch = 20\n",
    "model_name = 'LSTM'\n",
    "\n",
    "# Train on last 500 prices and try to predict the next price\n",
    "look_back = 500\n",
    "time_ahead = 1\n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test data: GBP USD exchange rate, 2006-2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pyfinancialdata.get_multi_year(\n",
    "    provider='oanda',\n",
    "    instrument='GBP_USD',\n",
    "    years=[2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015],\n",
    "    time_group='12h',\n",
    "    price_calculation='close',\n",
    "    drop_non_price_columns=True,\n",
    ")\n",
    "\n",
    "test_data = pyfinancialdata.get_multi_year(\n",
    "    provider='oanda',\n",
    "    instrument='GBP_USD',\n",
    "    years=[2015, 2016, 2017],\n",
    "    time_group='12h',\n",
    "    price_calculation='close'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_dataset(dataset, look_back, time_ahead):\n",
    "    '''\n",
    "    Converts an array of values into a dataset matrix of X and Y for a sequential model\n",
    "    '''\n",
    "    dataX, dataY = [], []\n",
    "\n",
    "    for i in range(len(dataset) - look_back - time_ahead + 1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back + time_ahead - 1, 0])\n",
    "\n",
    "    dataX = np.array(dataX)\n",
    "    dataX = np.reshape(dataX, (dataX.shape[0], 1, dataX.shape[1]))\n",
    "    dataY = np.array(dataY)\n",
    "\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset from the DataFrame and normalise\n",
    "dataset = train_data['price'].values\n",
    "dataset = dataset.astype('float32')\n",
    "dataset = dataset.reshape(-1, 1)\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "# Create X, Y for training\n",
    "trainX, trainY = create_training_dataset(dataset, look_back=look_back, time_ahead=time_ahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x136ea3610>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=epoch, batch_size=1, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to scale and predict\n",
    "def predict(values):\n",
    "    values = values.reshape(-1, 1)\n",
    "    # Create and fit scaler\n",
    "    local_scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    local_scaler.fit(values)\n",
    "    values = local_scaler.transform(values)\n",
    "    values = np.reshape(values, (1, 1, look_back))\n",
    "    prediction = model.predict(values)\n",
    "    prediction = prediction.reshape(-1, 1)\n",
    "    return local_scaler.inverse_transform(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put predictions from model into the dataframe with the test prices\n",
    "test_data['prediction_next'] = test_data['price'].rolling(window=look_back).apply(predict, raw=True)\n",
    "test_data['prediction'] = test_data['prediction_next'].shift(time_ahead)\n",
    "test_data.dropna(subset=['prediction_next'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.01674455647048089\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "rmse = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        y_true=test_data.dropna()['price'].values,\n",
    "        y_pred=test_data.dropna()['prediction'].values\n",
    "    )\n",
    ")\n",
    "print('RMSE: {0}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns for price direction and predicted direction\n",
    "test_data['next_direction'] = np.where(test_data['price'] > test_data['price'].shift(-1), -1, 1)\n",
    "test_data['next_direction_prediction'] = np.where(test_data['prediction_next'] > test_data['price'], 1, -1)\n",
    "test_data['correct'] = test_data['next_direction_prediction'] == test_data['next_direction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     612\n",
       "False    598\n",
       "Name: correct, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How often does the model predict the correct price change direction\n",
    "test_data['correct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trades from predictions\n",
    "positions = pd.DataFrame()\n",
    "positions['price'] = test_data['price']\n",
    "positions['high'] = test_data['high']\n",
    "positions['low'] = test_data['low']\n",
    "positions['position'] = np.where(test_data['prediction_next'] > test_data['price'], 1, -1)\n",
    "positions['position_group'] = (positions['position'].diff(1) != 0).astype('int').cumsum()\n",
    "positions['position_group_shifted'] = positions['position_group'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trades = pd.DataFrame({\n",
    "        'enter_date': positions.reset_index().groupby('position_group').date.first(),\n",
    "        'enter_price': positions.reset_index().groupby('position_group')['price'].first(),\n",
    "        'in_position_price_min': positions.reset_index().groupby('position_group_shifted')['low'].min(),\n",
    "        'in_position_price_max': positions.reset_index().groupby('position_group_shifted')['high'].max(),\n",
    "        'exit_date': positions.reset_index().groupby('position_group_shifted').date.last(),\n",
    "        'exit_price': positions.reset_index().groupby('position_group_shifted')['price'].last(),\n",
    "        'position_length': positions.groupby('position_group').size(),\n",
    "        'position': positions.groupby('position_group')['position'].first(),\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "trades['profit'] = ((trades['exit_price'] - trades['enter_price']) * trades['position'])\n",
    "trades['profitable'] = trades['profit'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     82\n",
       "False    33\n",
       "Name: profitable, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How often are the trades profitable?\n",
    "trades['profitable'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profitability: 71%\n"
     ]
    }
   ],
   "source": [
    "print('Profitability: {0}%'.format(\n",
    "    round(len(trades.loc[trades['profitable'] == True]) / len(trades) * 100)\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
